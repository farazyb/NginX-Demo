name: Deploy (ECR Public → AWS EKS)

on:
  push:
    branches: [ "main" ]
  workflow_dispatch: {}

permissions:
  id-token: write     # required for GitHub→AWS OIDC
  contents: read

env:
  # --- EKS/cluster settings ---
  AWS_REGION_EKS: eu-north-1
  EKS_CLUSTER_NAME: amazing-synth-shark
  NAMESPACE: default
  MANIFEST: resources.yaml

  # --- ECR Public settings ---
  # ECR Public control plane is in us-east-1
  ECR_PUBLIC_REGION: us-east-1
  ECR_PUBLIC_REPO: public.ecr.aws/y3l1h6z1/nginx

  # Image/version
  IMAGE_TAG: ${{ github.sha }}

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # OIDC → assume your IAM role (no static keys)
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::644701780664:role/GitHubActionsEKSRole
          role-session-name: GitHub_to_AWS_via_OIDC
          aws-region: ${{ env.AWS_REGION_EKS }}

      # Login to ECR Public (global endpoint; region must be us-east-1)
      - name: Login to Amazon ECR Public
        run: |
          aws ecr-public get-login-password --region "${ECR_PUBLIC_REGION}" \
            | docker login --username AWS --password-stdin public.ecr.aws

      # Build & push image to ECR Public
      - name: Build and push image
        env:
          IMAGE_URI: ${{ env.ECR_PUBLIC_REPO }}:${{ env.IMAGE_TAG }}
        run: |
          docker build -t "${IMAGE_URI}" .
          docker push "${IMAGE_URI}"
          echo "IMAGE=${IMAGE_URI}" >> "$GITHUB_ENV"
          echo "Pushed ${IMAGE_URI}"

      # Install kubectl (stable)
      - name: Install kubectl
        run: |
          KUBECTL_VERSION=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/
          kubectl version --client

      # Build a fresh kubeconfig (do NOT pass --role-arn; we already assumed it)
      - name: Update kubeconfig
        run: |
          rm -rf ~/.kube && mkdir -p ~/.kube
          aws eks update-kubeconfig \
            --name "${EKS_CLUSTER_NAME}" \
            --region "${AWS_REGION_EKS}"
          kubectl config current-context

      # (Optional) Quick identity checks while stabilizing
      - name: Who am I (AWS)?
        run: aws sts get-caller-identity
      - name: Who am I (K8s)?
        run: kubectl auth can-i --list || true

      # Render manifest (your resources.yaml uses ${IMAGE})
      - name: Render manifest
        run: |
          command -v envsubst >/dev/null 2>&1 || { sudo apt-get update && sudo apt-get install -y gettext-base; }
          envsubst < "${MANIFEST}" > out.yaml
          echo "Rendered with IMAGE=${IMAGE}"
          sed -n '1,200p' out.yaml

      # Ensure namespace exists (idempotent; skip schema validation)
      - name: Ensure namespace
        run: |
          kubectl create namespace "${NAMESPACE}" --dry-run=client -o yaml \
          | kubectl apply -f - --validate=false

      # Apply and wait for rollout (skip schema validation while testing)
      - name: Deploy to EKS
        run: |
          kubectl apply -n "${NAMESPACE}" -f out.yaml --validate=false
          kubectl rollout status deploy/nginx -n "${NAMESPACE}" --timeout=180s
          kubectl get pods -n "${NAMESPACE}"
          kubectl get svc -n "${NAMESPACE}" -o wide
